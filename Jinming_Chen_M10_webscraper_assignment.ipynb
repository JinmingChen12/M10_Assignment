{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install selenium\n",
    "\n",
    "###Load libraries\n",
    "import awscli\n",
    "import selenium\n",
    "import boto3\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "from selenium import webdriver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part I. Create web-scraper to load csv file into S3 Bucket "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<selenium.webdriver.remote.webelement.WebElement (session=\"aec6f06d8102b179aecc25545d73feca\", element=\"7cb212d0-5ccf-46e9-abb5-eeadf4471231\")>\n"
     ]
    }
   ],
   "source": [
    "####\n",
    "#Author: brandon chiazza\n",
    "#version 1.0\n",
    "#references: \n",
    "#https://www.programiz.com/python-programming/working-csv-files\n",
    "#https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/s3.html#S3.Client.create_bucket\n",
    "#https://realpython.com/python-boto3-aws-s3/\n",
    "#CLI aws s3api create-bucket --bucket my-bucket-name --region us-west-2 --create-bucket-configuration LocationConstraint=us-west-2\n",
    "#https://robertorocha.info/setting-up-a-selenium-web-scraper-on-aws-lambda-with-python/ \n",
    "##\n",
    "\n",
    "\n",
    "####SCRAPE THE WEBSITE######\n",
    "###call the webdriver\n",
    "browser = webdriver.Chrome(r\"C:\\Users\\11946/chromedriver.exe\")\n",
    "\n",
    "#enter the url path that needs to be accessed by webdriver\n",
    "browser.get('https://www.charitiesnys.com/RegistrySearch/search_charities.jsp')\n",
    "\n",
    "#identify xpath of location to select element\n",
    "inputElement = browser.find_element_by_xpath(\"/html/body/div/div[2]/div/table/tbody/tr/td[2]/div/div/font/font/font/font/font/font/table/tbody/tr[4]/td/form/table/tbody/tr[2]/td[2]/input[1]\")\n",
    "inputElement.send_keys('0')\n",
    "inputElement1 = browser.find_element_by_xpath(\"/html/body/div/div[2]/div/table/tbody/tr/td[2]/div/div/font/font/font/font/font/font/table/tbody/tr[4]/td/form/table/tbody/tr[10]/td/input[1]\").click()\n",
    "\n",
    "#identify the table to scrape\n",
    "table = browser.find_element_by_css_selector('table.Bordered')\n",
    "\n",
    "print(table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Organization Name</th>\n",
       "      <th>NY Reg #</th>\n",
       "      <th>EIN</th>\n",
       "      <th>Registrant Type</th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"Studio 5404\" Inc.</td>\n",
       "      <td>44-39-58</td>\n",
       "      <td>463180470</td>\n",
       "      <td>NFP</td>\n",
       "      <td>MASSAPAQUA</td>\n",
       "      <td>NY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"THEY ARE HAITIAN\" FUND, INC.</td>\n",
       "      <td>20-63-46</td>\n",
       "      <td>300170128</td>\n",
       "      <td>NFP</td>\n",
       "      <td>HUDSON</td>\n",
       "      <td>NY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(ASMA) American Syrian Multicultural Associati...</td>\n",
       "      <td>42-84-63</td>\n",
       "      <td>273130182</td>\n",
       "      <td>NFP</td>\n",
       "      <td>BROOKLYN</td>\n",
       "      <td>NY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>#HicksStrong Inc.</td>\n",
       "      <td>48-10-48</td>\n",
       "      <td>842612081</td>\n",
       "      <td>NFP</td>\n",
       "      <td>CLIFTON PARK</td>\n",
       "      <td>NY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>#WalkAway Foundation</td>\n",
       "      <td>47-15-80</td>\n",
       "      <td>832820906</td>\n",
       "      <td>NFP</td>\n",
       "      <td>CARLSBAD</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>04/11 10:17 PM test</td>\n",
       "      <td>47-13-95</td>\n",
       "      <td>206256427</td>\n",
       "      <td>NFP</td>\n",
       "      <td>ALBANY</td>\n",
       "      <td>NY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1/20/21 Action Fund</td>\n",
       "      <td>46-99-13</td>\n",
       "      <td>832210730</td>\n",
       "      <td>NFP</td>\n",
       "      <td>SAN FRANCISCO</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10/40 Connections, Inc.</td>\n",
       "      <td>45-70-15</td>\n",
       "      <td>621825230</td>\n",
       "      <td>NFP</td>\n",
       "      <td>HIXSON</td>\n",
       "      <td>TN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1000 Feet Project, Inc</td>\n",
       "      <td>45-00-14</td>\n",
       "      <td>473820859</td>\n",
       "      <td>NFP</td>\n",
       "      <td>NEW YORK</td>\n",
       "      <td>NY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1000 Islands Hose Haulers</td>\n",
       "      <td>45-38-38</td>\n",
       "      <td>454570241</td>\n",
       "      <td>NFP</td>\n",
       "      <td>CARTHAGE</td>\n",
       "      <td>NY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1004 Foundation, Inc.</td>\n",
       "      <td>45-00-13</td>\n",
       "      <td>463110658</td>\n",
       "      <td>NFP</td>\n",
       "      <td>LONG ISLAND CITY</td>\n",
       "      <td>NY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>100 BLACK MEN OF LONG ISLAND DEVELOPMENT GROUP...</td>\n",
       "      <td>20-08-47</td>\n",
       "      <td>113617702</td>\n",
       "      <td>NFP</td>\n",
       "      <td>HEMPSTEAD</td>\n",
       "      <td>NY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>100 BLACKS WHO CARE INC</td>\n",
       "      <td>06-42-84</td>\n",
       "      <td>311628801</td>\n",
       "      <td>NFP</td>\n",
       "      <td>BROOKLYN</td>\n",
       "      <td>NY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>100 BLACK WOMEN OF LONG ISLAND FOUNDATION INC</td>\n",
       "      <td>05-79-45</td>\n",
       "      <td>113101805</td>\n",
       "      <td>NFP</td>\n",
       "      <td>GARDEN CITY</td>\n",
       "      <td>NY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>100Cameras, Inc.</td>\n",
       "      <td>43-16-19</td>\n",
       "      <td>264692506</td>\n",
       "      <td>NFP</td>\n",
       "      <td>NEW YORK</td>\n",
       "      <td>NY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Organization Name  NY Reg #        EIN  \\\n",
       "1                                  \"Studio 5404\" Inc.  44-39-58  463180470   \n",
       "2                       \"THEY ARE HAITIAN\" FUND, INC.  20-63-46  300170128   \n",
       "3   (ASMA) American Syrian Multicultural Associati...  42-84-63  273130182   \n",
       "4                                   #HicksStrong Inc.  48-10-48  842612081   \n",
       "5                                #WalkAway Foundation  47-15-80  832820906   \n",
       "6                                 04/11 10:17 PM test  47-13-95  206256427   \n",
       "7                                 1/20/21 Action Fund  46-99-13  832210730   \n",
       "8                             10/40 Connections, Inc.  45-70-15  621825230   \n",
       "9                              1000 Feet Project, Inc  45-00-14  473820859   \n",
       "10                          1000 Islands Hose Haulers  45-38-38  454570241   \n",
       "11                              1004 Foundation, Inc.  45-00-13  463110658   \n",
       "12  100 BLACK MEN OF LONG ISLAND DEVELOPMENT GROUP...  20-08-47  113617702   \n",
       "13                            100 BLACKS WHO CARE INC  06-42-84  311628801   \n",
       "14      100 BLACK WOMEN OF LONG ISLAND FOUNDATION INC  05-79-45  113101805   \n",
       "15                                   100Cameras, Inc.  43-16-19  264692506   \n",
       "\n",
       "   Registrant Type              City State  \n",
       "1              NFP        MASSAPAQUA    NY  \n",
       "2              NFP            HUDSON    NY  \n",
       "3              NFP          BROOKLYN    NY  \n",
       "4              NFP      CLIFTON PARK    NY  \n",
       "5              NFP          CARLSBAD    CA  \n",
       "6              NFP            ALBANY    NY  \n",
       "7              NFP     SAN FRANCISCO    CA  \n",
       "8              NFP            HIXSON    TN  \n",
       "9              NFP          NEW YORK    NY  \n",
       "10             NFP          CARTHAGE    NY  \n",
       "11             NFP  LONG ISLAND CITY    NY  \n",
       "12             NFP         HEMPSTEAD    NY  \n",
       "13             NFP          BROOKLYN    NY  \n",
       "14             NFP       GARDEN CITY    NY  \n",
       "15             NFP          NEW YORK    NY  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#####CREATE DATE FRAME#####\n",
    "#create empty dataframe\n",
    "df =[]\n",
    "\n",
    "#loop through dataframe to export table\n",
    "for row in table.find_elements_by_css_selector('tr'):\n",
    "      cols = df.append([cell.text for cell in row.find_elements_by_css_selector('td')])\n",
    "\n",
    "\n",
    "#update dataframe with header \n",
    "df = pd.DataFrame(df, columns = [\"Organization Name\", \"NY Reg #\", \"EIN\" ,\"Registrant Type\",\"City\",\"State\"])\n",
    "\n",
    "#remove the blank row in the csv output file\n",
    "df = df.iloc[1:]\n",
    "\n",
    "display(df) #let's have a look at the data before creating the CSV file and loading it into s3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfull uploaded file to location:s3:/jinming/charities_bureau_scrape_20210407232059.csv\n"
     ]
    }
   ],
   "source": [
    "###LOAD THE FILE INTO S3####\n",
    "# prepare csv file name   \n",
    "pathname = 's3:/jinming/'#specify location of s3:/{my-bucket}/\n",
    "filename= 'charities_bureau_scrape_' #name of your group\n",
    "datetime = time.strftime(\"%Y%m%d%H%M%S\") #timestamp\n",
    "filenames3 = \"%s%s%s.csv\"%(pathname,filename,datetime) #name of the filepath and csv file\n",
    "\n",
    "#load file into s3. Pandas actually leverages boto to connect to s3 and can push the file directly into an s3 bucket\n",
    "df.to_csv(filenames3, header=True, line_terminator='\\n') \n",
    "\n",
    "#print success message\n",
    "print(\"Successfull uploaded file to location:\"+str(filenames3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part II. Update web-scraper to iterate all results and load csv file into S3 Bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (<ipython-input-11-1bcf8566039e>, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-11-1bcf8566039e>\"\u001b[1;36m, line \u001b[1;32m6\u001b[0m\n\u001b[1;33m    next_page_link = driver.find_element_by_xpath(f'.//li[span = \"{current_page_number + 1}\"]')\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    current_page_number = int(driver.find_element_by_css_selector('li[data-testid=current-page-item]').text)\n",
    "\n",
    "    print(f\"Processing page {current_page_number}..\")\n",
    " \n",
    "        next_page_link = driver.find_element_by_xpath(f'.//li[span = \"{current_page_number + 1}\"]')\n",
    "        next_page_link.click()\n",
    "    except NoSuchElementException:\n",
    "        print(f\"Exiting. Last page: {current_page_number}.\")\n",
    "        break\n",
    "\n",
    "   # TODO: save the page"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import requests\n",
    "\n",
    "df1 =[]\n",
    "\n",
    "for page in range(10):\n",
    "\n",
    "    print('---', page, '---')\n",
    "\n",
    "    r = requests.get(table + str(page))\n",
    "\n",
    "    # String substitution for HTML\n",
    "    for link in soup.find_all(\"a\"):\n",
    "        print(\"<a href='>%s'>%s</a>\" % (link.get(\"href\"), link.text))\n",
    "\n",
    "    # Fetch and print general data from title class\n",
    "    general_data = soup.find_all('div', {\"Organization Name\", \"NY Reg #\", \"EIN\" ,\"Registrant Type\",\"City\",\"State\"})\n",
    "\n",
    "    for item in general_data:\n",
    "        print(item.contents[0].text)\n",
    "        print(item.contents[1].text.replace('.',''))\n",
    "        print(item.contents[2].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from requests import get\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Organization Name</th>\n",
       "      <th>NY Reg #</th>\n",
       "      <th>EIN</th>\n",
       "      <th>Registrant Type</th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Organization Name, NY Reg #, EIN, Registrant Type, City, State]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df =[]\n",
    "#url = \"https://www.charitiesnys.com/RegistrySearch/search_charities_action.jsp\"\n",
    "#headers = {\"Accept-Language\": \"en-US, en;q=0.5\"}\n",
    "results = requests.get(url, headers=headers)\n",
    "\n",
    "soup = BeautifulSoup(results.text, \"html.parser\")\n",
    "\n",
    "#initiate data storage\n",
    "Organization_Name = []\n",
    "NY_Reg_Number = []\n",
    "EIN = []\n",
    "Registrant_Type = []\n",
    "City = []\n",
    "State = []\n",
    "\n",
    "\n",
    "df = soup.find_all('div', class_='lister-item mode-advanced')\n",
    "\n",
    "#our loop through each container\n",
    "for container in df:\n",
    "\n",
    "  # Organization Name\", \"NY Reg #\", \"EIN\" ,\"Registrant Type\",\"City\",\"State      \n",
    "        #Organization_Name = container.h3.a.text\n",
    "        # titles.append(Organization_Name)\n",
    "        \n",
    "        #year\n",
    "        Organization_Name = container.h3.find('span', class_='Organization Name').text\n",
    "        name.append(Organization_Name)\n",
    "\n",
    "        # runtime\n",
    "        NY_Reg_Number = container.p.find('span', class_='NY Reg #').text if container.p.find('span', class_='NY Reg #').text else '-'\n",
    "        number.append(NY_Reg_Number)\n",
    "\n",
    "        #IMDb rating\n",
    "        EIN = float(container.strong.text)\n",
    "        EIN.append(EIN)\n",
    "\n",
    "        #metascore\n",
    "        Registrant_Type = container.find('span', class_='Registrant Type').text if container.find('span', class_='Registrant Type') else '-'\n",
    "        Registrant_Type.append(Registrant_Type)\n",
    "\n",
    "        \n",
    "        City = container.h3.find('span', class_='City').text\n",
    "        city.append(City)\n",
    "\n",
    "        \n",
    "        State = container.h3.find('span', class_='State').text\n",
    "        state.append(State)\n",
    "\n",
    "#pandas dataframe        \n",
    "df = pd.DataFrame(df, columns = [\"Organization Name\", \"NY Reg #\", \"EIN\" ,\"Registrant Type\",\"City\",\"State\"])\n",
    "\n",
    "#remove the blank row in the csv output file\n",
    "df = df.iloc[1:]\n",
    "\n",
    "display(df) #let's have a look at the data before creating the CSV file and loading it into s3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "  \n",
    "URL = 'https://www.charitiesnys.com/RegistrySearch/search_charities_action.jsp'\n",
    "  \n",
    "req = requests.get(URL)\n",
    "soup = bs(req.text, 'html.parser')\n",
    "  \n",
    "titles = soup.find_all('div',attrs = {\"Organization Name\", \"NY Reg #\", \"EIN\" ,\"Registrant Type\",\"City\",\"State\"})\n",
    "  \n",
    "print(titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-8ac07eaa5a12>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"{(i-3)+page*15}\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mtitles\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"{i-3}\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mtitles\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "\n",
    "  \n",
    "for page in range(1,10):\n",
    "      # pls note that the total number of\n",
    "    # pages in the website is more than 5000 so i'm only taking the\n",
    "    # first 10 as this is just an example\n",
    "  \n",
    "    req = requests.get(URL + str(page) + '/')\n",
    "    soup = bs(req.text, 'html.parser')\n",
    "  \n",
    "    titles = soup.find_all('div',attrs={'class','head'})\n",
    "  \n",
    "    for i in range(4,19):\n",
    "        if page>1:\n",
    "            print(f\"{(i-3)+page*15}\" + titles[i].text)\n",
    "        else:\n",
    "            print(f\"{i-3}\" + titles[i].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
